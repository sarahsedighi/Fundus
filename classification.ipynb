{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVrIYVVF0fzw"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxpUBtvTySEq"
   },
   "outputs": [],
   "source": [
    "# Global imports\n",
    "import os \n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm, trange\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "chx4YlRf5NCQ",
    "outputId": "7858a7e8-2c07-446b-a0f6-4933a144fac6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpJZYRza0lWR"
   },
   "source": [
    "# Dataset prepration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.RandomRotation(degrees=(-15, 15)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "AeBpRwIYzN5k",
    "outputId": "6b870380-a962-4505-ef64-aad1935b7e6e"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self , dataset_path , annotation_path , phase = None , transform = None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.annotations = pd.read_csv(annotation_path)\n",
    "        self.main_data_files = os.listdir(self.dataset_path)\n",
    "        sorted(self.main_data_files)\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.dataset_path + self.main_data_files[idx]\n",
    "\n",
    "        # Read images:\n",
    "        image = cv2.imread(image_path)\n",
    "        #image = (image/255).astype(\"float32\") # Network needs inputs in range 0-1\n",
    "        \n",
    "        # Read label:\n",
    "        class_ = self.annotations.loc[self.annotations[\"image\"] == self.main_data_files[idx][:-5]]['level'].values[0]\n",
    "        class_ = int(class_)\n",
    "        \n",
    "        # Perform transformation:\n",
    "        if self.transform == None:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image , class_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.main_data_files)\n",
    "    \n",
    "    def path_sampler(self):\n",
    "        self.annotations = self.annotations.sort_values(by = ['level' , 'image'])    \n",
    "        max_counts = self.annotations['level'].value_counts(ascending=True).iloc[-1]\n",
    "        grouped = self.annotations.groupby('level')\n",
    "        augmented_images_name = []\n",
    "        for level in range(5):\n",
    "            this_group = grouped.get_group(level)\n",
    "            group_counts = this_group.shape[0]\n",
    "            if group_counts == max_counts:\n",
    "                image_names = this_group['image'].tolist()\n",
    "                augmented_images_name.append(image_names)\n",
    "            if group_counts < max_counts:\n",
    "                image_names = this_group['image'].tolist()\n",
    "                main_counts = len(image_names)\n",
    "                i = 0\n",
    "                while len(image_names) < max_counts:\n",
    "                    image_names.append(image_names[i])\n",
    "                    i += 1\n",
    "                    if i == main_counts:\n",
    "                        i = 0\n",
    "                \n",
    "                augmented_images_name.append(image_names)\n",
    "        augmented_images_name = [x + '.jpeg' for sublist in augmented_images_name for x in sublist]\n",
    "        return augmented_images_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_mean_std(loader):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for data, _ in tqdm(loader):\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_sqrd_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_sqrd_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std   \n",
    "    \n",
    "mean , std = get_mean_std(train_loader)\n",
    "\n",
    "print(mean , std)\n",
    "'''\n",
    "\n",
    "# Main train_loader: mean:   mean = [0.3045, 0.3578, 0.4824] , std= [0.2182, 0.2242, 0.2571]\n",
    "# Main val_loader: mean:     mean = [0.3049, 0.3587, 0.4833] , std = [0.2188, 0.2247, 0.2572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "\n",
    "BATCH_SIZE = 32 \n",
    "\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "dataloaders_dict = {'train' : train_loader , 'val' : val_loader  }\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fDDpnLzs9Px"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    if feature_extracting == False:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdvvFxLE1vq-"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        print(model_name)\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet34\":\n",
    "        \"\"\" Resnet34\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg11\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == \"vgg19\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg19(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "        \n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggvlNEmf1397"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train' , 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            i = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                i += 1\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "\n",
    "                    else:                \n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                 \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            print('Phase: {}, Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                PATH = \"best_Model_\"+ str(epoch) + \".pt\"\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print('-' * 100)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You need just change this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"train/\"\n",
    "val_dataset_path = \"val/\"\n",
    "\n",
    "image_annotation = {\"train/\": \"train_1.csv\" , \n",
    "                    \"val/\" : \"trainLabels.csv\" , \n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0aDcXpd17pK"
   },
   "outputs": [],
   "source": [
    "# Name of model\n",
    "model_name = \"inception\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 5\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Learning rate of model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract =False\n",
    "\n",
    "# Flag for using pretrain weights\n",
    "use_pretrained=True\n",
    "\n",
    "# Initialize the model for this run\n",
    "model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Send the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "train_dataset = MyDataset(dataset_path = train_dataset_path , annotation_path = image_annotation[train_dataset_path] , phase = 'train' , transform = train_transforms)\n",
    "val_dataset = MyDataset(dataset_path = val_dataset_path , annotation_path = image_annotation[val_dataset_path] , phase = 'val', transform = val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE,  shuffle = True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE,  shuffle = True, num_workers=0)\n",
    "\n",
    "dataloaders_dict = {'train' : train_loader , \"val\" : val_loader  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oRVqP251-Ib"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE )\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainig model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUksvmMq2A8a",
    "outputId": "6fda4f70-69de-4f9e-8c6a-4d40b19df303",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, val_acc_history = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs = num_epochs , is_inception = (model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./best_Model_9.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model , loader , criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    All_preds = []\n",
    "    All_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            labels =  labels.to(device)\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds , labels)\n",
    "            test_loss += loss\n",
    "            preds = torch.argmax(preds , dim = 1)\n",
    "            All_preds.append(preds.cpu().numpy())\n",
    "            All_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            correct += (preds == labels).float().sum()\n",
    "        print(labels)\n",
    "        print(preds)\n",
    "        accuracy = correct / len(loader.dataset)    \n",
    "        epoch_loss = test_loss / len(loader.dataset)\n",
    "        print(\"   loss:%.2f\" %epoch_loss.item())\n",
    "        All_labels = np.concatenate( All_labels, axis=0 )\n",
    "        All_preds = np.concatenate( All_preds, axis=0 )\n",
    "    return All_labels ,All_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_labels ,All_preds = test(model , val_loader , criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(All_labels ,All_preds ))\n",
    "print()\n",
    "print(classification_report(All_labels ,All_preds ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Race_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
